\section{Conclusion}
\label{sec:conclusion}

In this paper we present a new algorithm created by combining sequential experiment selection and models of optimal foraging with an information theoretic reward function.  For certain regimes of operation the new algorithm is significantly better the control algorithm based on optimal experiment design alone.  Additionally this work continues the process of introducing sequential selection to the field of science autonomy.  

From the experiment presented in this paper we can conclude three things.  First, for small sampling costs relative to the transect duration the foraging algorithm produces about a 50\% reduction in accumulated error.  For the small sampling costs the effect size is substantial and our Bayesian paired t-test gives us 95\% confidence that the increase in performance is non-zero.

Second, when the sampling cost is large relative to the duration of the transect Uniform sampling is as good as or better than foraging.  This makes sense, as the first samples one collects are the most informative about a distribution.  Distributing samples across the different classes of objects increases the overall rate of information gained, ensuring the greatest short-term reduction in error.

Thirdly, when the sampling cost gets sufficiently large foraging again becomes a competative algorithm.  The convergence in performance is mainly due to the very limited ability to sample and consequent poor performance of both algorithm.  

This work does not address perception and requires some system to parse scenes to identify the classes available to the robot.  This is necessary for fielding this algorithm on a robot.  The algorithm does not account for the following deviations in the problem setting: If there is more than one type of sensor with a different cost to use; Class arrival rates that change over time; Class distributions changing over time.  These need to be addressed in the future to make a more plausible robot scientist.  It is the desire of the authors to make the agent responsible not just for collecting data, but to generate and test hypotheses about the environment.
% 
% 1. Implement on a real robot (of course).  Integrate some sensor processing algorithm (texturecam?) to abstract from images/whatever to categories as used in this paper.
% 
% 2. Multi-objective optimization (different sensors with different costs)
% 
% 3. Vary the arrival rates much more (have sims set up for that, haven't finished executing them yet.  Seriously! Yes, yes, write it in C next time.)
% 
% 4. Handle when the distributions change. 
% 
% 5. Handle when arrival rates change.




